{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important: We are using PIL to read .png files later.\n",
    "# This was done on purpose to read indexed png files\n",
    "# in a special way -- only indexes and not map the indexes\n",
    "# to actual rgb values. This is specific to PASCAL VOC\n",
    "# dataset data. If you don't want thit type of behaviour\n",
    "# consider using skimage.io.imread()\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import tensorflow as tf\n",
    "import nibabel as nib\n",
    "\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nii(img_path):\n",
    "    \"\"\"\n",
    "    Function to load a 'nii' or 'nii.gz' file, The function returns\n",
    "    everyting needed to save another 'nii' or 'nii.gz'\n",
    "    in the same dimensional space, i.e. the affine matrix and the header\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    img_path: string\n",
    "    String with the path of the 'nii' or 'nii.gz' image file name.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Three element, the first is a numpy array of the image values,\n",
    "    the second is the affine transformation of the image, and the\n",
    "    last one is the header of the image.\n",
    "    \"\"\"\n",
    "    nimg = nib.load(img_path)\n",
    "    return nimg.get_data(), nimg.affine, nimg.header\n",
    "\n",
    "\n",
    "def save_nii(img_path, data, affine, header):\n",
    "    \"\"\"\n",
    "    Function to save a 'nii' or 'nii.gz' file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    img_path: string\n",
    "    Path to save the image should be ending with '.nii' or '.nii.gz'.\n",
    "\n",
    "    data: np.array\n",
    "    Numpy array of the image data.\n",
    "\n",
    "    affine: list of list or np.array\n",
    "    The affine transformation to save with the image.\n",
    "\n",
    "    header: nib.Nifti1Header\n",
    "    The header that define everything about the data\n",
    "    (pleasecheck nibabel documentation).\n",
    "    \"\"\"\n",
    "    nimg = nib.Nifti1Image(data, affine=affine, header=header)\n",
    "    nimg.to_filename(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for defining tf types\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_image_annotation_pairs_to_tfrecord(filename_pairs, tfrecords_filename):\n",
    "    \"\"\"Writes given image/annotation pairs to the tfrecords file.\n",
    "    The function reads each image/annotation pair given filenames\n",
    "    of image and respective annotation and writes it to the tfrecord\n",
    "    file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename_pairs : array of tuples (img_filepath, annotation_filepath)\n",
    "        Array of tuples of image/annotation filenames\n",
    "    tfrecords_filename : string\n",
    "        Tfrecords filename to write the image/annotation pairs\n",
    "    \"\"\"\n",
    "    writer = tf.python_io.TFRecordWriter(tfrecords_filename)\n",
    "\n",
    "    #for img_path, annotation_path in filename_pairs:\n",
    "    for img_path,annotation_path in filename_pairs:\n",
    "        img = np.load(img_path) \n",
    "        annotation = np.load(annotation_path)\n",
    "        #print(annotation.shape)\n",
    "        #print(annotation)\n",
    "        \n",
    "\n",
    "        #img = np.array(Image.open(img_path))\n",
    "        \n",
    "        #annotation = np.array(Image.open(annotation_path))\n",
    "        \n",
    "        # Unomment this one when working with surgical data\n",
    "        # annotation = annotation[:, :, 0]\n",
    "\n",
    "        # The reason to store image sizes was demonstrated\n",
    "        # in the previous example -- we have to know sizes\n",
    "        # of images to later read raw serialized string,\n",
    "        # convert to 1d array and convert to respective\n",
    "        # shape that image used to have.\n",
    "        #height = img.shape[0] \n",
    "        height = img[0].shape[0] \n",
    "        \n",
    "        #width = img.shape[1]\n",
    "        width = img[0].shape[1] \n",
    "        \n",
    "        #add depth \n",
    "        depth = img[0].shape[2]\n",
    "        #print(depth)\n",
    "        #print(img[0].shape) #288,288,140 \n",
    "\n",
    "\n",
    "        #img_raw = img.tostring()\n",
    "        img_raw=img[0].tostring()\n",
    "        annotation_raw = annotation[0].tostring()\n",
    "        print(annotation[0].shape)\n",
    "        #print(annotation[1].shape)\n",
    "        #print(annotation[2].shape)\n",
    "        \n",
    "    \n",
    "        #print(annotation_raw)\n",
    "        #annotation_raw = annotation.tostring()\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'height': _int64_feature(height),\n",
    "            'width': _int64_feature(width),\n",
    "            'depth': _int64_feature(depth), \n",
    "            'image_raw': _bytes_feature(img_raw),\n",
    "            'mask_raw': _bytes_feature(annotation_raw)}))\n",
    "\n",
    "        writer.write(example.SerializeToString())\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "def read_image_annotation_pairs_from_tfrecord(tfrecords_filename):\n",
    "    \"\"\"Return image/annotation pairs from the tfrecords file.\n",
    "    The function reads the tfrecords file and returns image\n",
    "    and respective annotation matrices pairs.\n",
    "    Parameters\n",
    "    ----------\n",
    "    tfrecords_filename : string\n",
    "        filename of .tfrecords file to read from\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    image_annotation_pairs : array of tuples (img, annotation)\n",
    "        The image and annotation that were read from the file\n",
    "    \"\"\"\n",
    "    \n",
    "    image_annotation_pairs = []\n",
    "\n",
    "    record_iterator = tf.python_io.tf_record_iterator(path=tfrecords_filename)\n",
    "\n",
    "    for string_record in record_iterator:\n",
    "\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(string_record)\n",
    "\n",
    "        height = int(example.features.feature['height']\n",
    "                                     .int64_list\n",
    "                                     .value[0])\n",
    "\n",
    "        width = int(example.features.feature['width']\n",
    "                                    .int64_list\n",
    "                                    .value[0])\n",
    "        \n",
    "        depth = int(example.features.feature['depth']\n",
    "                                    .int64_list\n",
    "                                    .value[0])\n",
    "\n",
    "        img_string = (example.features.feature['image_raw']\n",
    "                                      .bytes_list\n",
    "                                      .value[0])\n",
    "\n",
    "        annotation_string = (example.features.feature['mask_raw']\n",
    "                                    .bytes_list\n",
    "                                    .value[0])\n",
    "\n",
    "        img_1d = np.fromstring(img_string, dtype=np.uint8)\n",
    "        img = img_1d.reshape((height, width, depth, -1))\n",
    "\n",
    "        annotation_1d = np.fromstring(annotation_string, dtype=np.uint8)\n",
    "\n",
    "        # Annotations don't have depth (3rd dimension)\n",
    "        # TODO: check if it works for other datasets\n",
    "        annotation = annotation_1d.reshape((height, width, depth,-1))\n",
    "\n",
    "        image_annotation_pairs.append((img, annotation))\n",
    "    \n",
    "    return image_annotation_pairs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_tfrecord_and_decode_into_image_annotation_pair_tensors(tfrecord_filenames_queue):\n",
    "    \"\"\"Return image/annotation tensors that are created by reading tfrecord file.\n",
    "    The function accepts tfrecord filenames queue as an input which is usually\n",
    "    can be created using tf.train.string_input_producer() where filename\n",
    "    is specified with desired number of epochs. This function takes queue\n",
    "    produced by aforemention tf.train.string_input_producer() and defines\n",
    "    tensors converted from raw binary representations into\n",
    "    reshaped image/annotation tensors.\n",
    "    Parameters\n",
    "    ----------\n",
    "    tfrecord_filenames_queue : tfrecord filename queue\n",
    "        String queue object from tf.train.string_input_producer()\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    image, annotation : tuple of tf.int32 (image, annotation)\n",
    "        Tuple of image/annotation tensors\n",
    "    \"\"\"\n",
    "    \n",
    "    reader = tf.TFRecordReader()\n",
    "\n",
    "    _, serialized_example = reader.read(tfrecord_filenames_queue)\n",
    "\n",
    "    features = tf.parse_single_example(\n",
    "      serialized_example,\n",
    "      features={\n",
    "        'height': tf.FixedLenFeature([], tf.int64),\n",
    "        'width': tf.FixedLenFeature([], tf.int64),\n",
    "        'depth': tf.FixedLenFeature([], tf.int64), \n",
    "        'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "        'mask_raw': tf.FixedLenFeature([], tf.string)\n",
    "        })\n",
    "\n",
    "    \n",
    "    image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "    annotation = tf.decode_raw(features['mask_raw'], tf.uint8)\n",
    "    \n",
    "    height = tf.cast(features['height'], tf.int32)\n",
    "    width = tf.cast(features['width'], tf.int32) \n",
    "    depth = tf.cast(features['depth'],tf.int32)\n",
    "    \n",
    "    #image_shape = tf.pack([height, width, depth, 3])\n",
    "    image_shape = tf.stack([height, width, depth, 3])\n",
    "    \n",
    "    # The last dimension was added because\n",
    "    # the tf.resize_image_with_crop_or_pad() accepts tensors\n",
    "    # that have depth. We need resize and crop later.\n",
    "    # TODO: See if it is necessary and probably remove third\n",
    "    # dimension\n",
    "    annotation_shape = tf.stack([height, width, depth, 1])\n",
    "    \n",
    "    image = tf.reshape(image, image_shape)\n",
    "    annotation = tf.reshape(annotation, annotation_shape)\n",
    "    \n",
    "    return image, annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 160)\n"
     ]
    }
   ],
   "source": [
    "img_path=os.path.abspath('mr_train_1001_image.nii')\n",
    "label_path=os.path.abspath('mr_train_1001_label.nii')\n",
    "\n",
    "array_img=load_nii(img_path) \n",
    "array_label=load_nii(label_path) \n",
    "\n",
    "img_npy_path=os.path.abspath('mr_train_1001_img_npy')\n",
    "label_npy_path=os.path.abspath('mr_train_1001_label_npy')\n",
    "    \n",
    "np.save(img_npy_path, array_img) \n",
    "np.save(label_npy_path, array_label) \n",
    "\n",
    "\n",
    "img_npy_path=os.path.abspath('mr_train_1001_img_npy.npy')\n",
    "label_npy_path=os.path.abspath('mr_train_1001_label_npy.npy')\n",
    "\n",
    " \n",
    "f_arr=[[img_npy_path,label_npy_path]]\n",
    "\n",
    "\n",
    "tfrecords_filename='mr_train_1001_pairs.tfrecords'\n",
    "write_image_annotation_pairs_to_tfrecord(f_arr, tfrecords_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SeojinKim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:115: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "C:\\Users\\SeojinKim\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:118: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    }
   ],
   "source": [
    "pairs=read_image_annotation_pairs_from_tfrecord(tfrecords_filename) \n",
    "#print(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(?, ?, ?, 3), dtype=uint8)\n",
      "Tensor(\"Reshape_1:0\", shape=(?, ?, ?, 1), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "#print(pairs)  \n",
    "tfrecord_filenames_queue=tf.train.string_input_producer([\"mr_train_1001_pairs.tfrecords\"])\n",
    "img,annotation=read_tfrecord_and_decode_into_image_annotation_pair_tensors(tfrecord_filenames_queue)  \n",
    "print(img)\n",
    "print(annotation)\n",
    "#print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
